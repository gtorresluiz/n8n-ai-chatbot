# ü§ñ Agente de Suporte Operacional com IA (n8n + Google Gemini)

Este projeto demonstra a cria√ß√£o de um **Agente de Suporte Operacional** totalmente automatizado, capaz de responder a d√∫vidas de clientes em tempo real, utilizando uma base de conhecimento interna simulada do IFood e intelig√™ncia artificial (Google Gemini).

O fluxo de trabalho (workflow) √© constru√≠do na plataforma de automa√ß√£o **n8n**, garantindo que as respostas sejam r√°pidas, precisas e **validadas pelas instru√ß√µes internas do agente**.

---

## ‚ú® Destaques do Projeto

* **POC de Agente Interno:** Desenvolvimento de uma Prova de Conceito (POC) de Agente de IA para decis√µes operacionais (reembolso/cancelamento), utilizando uma **base de conhecimento simulada** de pol√≠ticas do iFood.
* **Processamento de Dados (RAG):** Demonstra a unifica√ß√£o de diferentes fontes de dados (JSON de requisi√ß√£o e Contexto Agrupado em CSV/Texto) utilizando o n√≥ `Merge` para alimentar o modelo (uma abordagem de **Retrieval-Augmented Generation - RAG**).
* **Controle de Qualidade Integrado:** A l√≥gica de *guard-rail* e o *fallback* para baixa confian√ßa foram **diretamente instru√≠dos no prompt do Agente LLM**. Isso simplifica o fluxo e aumenta a efici√™ncia, pois o agente √© o √∫nico respons√°vel por decidir se a resposta √© vi√°vel ou se deve usar a mensagem de fallback ("N√£o tenho pol√≠tica suficiente...").
* **Cen√°rios Cr√≠ticos Testados:** O fluxo foi testado com cen√°rios de alto risco operacional, como pedidos j√° despachados para entrega, falhas do restaurante e cobran√ßas indevidas ap√≥s o cancelamento.
* **Arquitetura:** Cria√ß√£o de um fluxo de trabalho ass√≠ncrono e resiliente para tarefas de suporte.

---

## ‚öôÔ∏è Arquitetura do Workflow

O fluxo √© dividido em tr√™s etapas principais. A principal mudan√ßa √© que a valida√ß√£o agora ocorre dentro do Agente (Etapa 2), e n√£o em um n√≥ `If` externo.

### 1. Prepara√ß√£o e Agrupamento de Dados

| N√≥ | Fun√ß√£o |
| :--- | :--- |
| **Webhook** | Recebe a requisi√ß√£o inicial do usu√°rio (a pergunta). |
| **Transforma√ß√£o de Dados** | Processa e agrupa a base de conhecimento (simulada) em uma √∫nica string (`meu_contexto_agrupado`). |
| **Set (Extrair Pergunta)** | Filtra o JSON do Webhook para extrair apenas a chave `pergunta_do_cliente`. |
| **Merge (Combine)** | Combina o objeto `pergunta_do_cliente` e o `meu_contexto_agrupado` em um **√∫nico objeto JSON**, pronto para ser injetado no LLM. |

### 2. Processamento da Intelig√™ncia Artificial e Decis√£o

| N√≥ | Fun√ß√£o |
| :--- | :--- |
| **Google Gemini Chat Model** | O Agente de IA recebe o JSON combinado e atua como um Agente Operacional. **Ele cont√©m toda a l√≥gica de decis√£o:** *Responde APENAS com a Base de Conhecimento* e *aplica o fallback autom√°tico* se a resposta n√£o for clara. |
| **Instru√ß√£o Chave (Prompt)** | O prompt inclui a regra: "Se n√£o encontrar resposta clara, responda: 'N√£o tenho pol√≠tica suficiente para responder isso. Encaminhe para suporte.'". Isso garante consist√™ncia operacional. |

### 3. Sa√≠da Controlada

| N√≥ | Fun√ß√£o |
| :--- | :--- |
| **Set (JSON Parser)** | Garante que a resposta de texto do LLM (que vem formatada como JSON, incluindo a chave `resposta` e `confianca`) seja convertida em um **objeto JSON** utiliz√°vel. |
| **Set (Resposta Limpa)** | Extrai a mensagem final (`resposta` do JSON) para ser enviada ao usu√°rio. |
| **A√ß√£o Final** | Envio da resposta ao canal de comunica√ß√£o do cliente. |

---

## üõ†Ô∏è Como Executar Este Projeto

Para importar e executar este workflow em sua pr√≥pria inst√¢ncia do n8n:

### Pr√©-requisitos

1.  Uma inst√¢ncia do **n8n** (self-hosted ou Cloud).
2.  Uma **API Key** v√°lida do **Google Gemini** (pode ser obtida gratuitamente no Google AI Studio).

### Passos de Execu√ß√£o

1.  **Clone o Reposit√≥rio:** Baixe ou clone este reposit√≥rio.
2.  **Importe o Workflow:**
    * Abra sua interface do n8n.
    * No painel principal, clique em **"New" > "Import from JSON"**.
    * Selecione o arquivo `[nome_do_seu_projeto].json` que voc√™ exportou.
3.  **Configure as Credenciais:**
    * Clique no n√≥ **Google Gemini Chat Model**.
    * Clique em **"Credentials"** e adicione sua **API Key do Gemini**.
4.  **Teste:** Execute o workflow ou envie uma requisi√ß√£o POST para o endere√ßo do Webhook configurado.
 4.1.
   *  Utiliziando **POSTMAN**
   *  M√©todo POST
     ```
      http://localhost:5678/webhook-test/ia-operacional
     ```
  * body
    ``` json
    {
      "pergunta": "O cliente pode pedir reembolso ap√≥s o pedido sair para entrega?"
    }
    ```

 ---

---

## ü§ù Conecte-se

Fique √† vontade para entrar em contato para discutir este projeto ou outras solu√ß√µes de automa√ß√£o e IA!
